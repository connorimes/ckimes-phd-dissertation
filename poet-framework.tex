\section{Design and Implementation}
\label{sec:poet-framework}

The goal of the resource allocation framework is twofold. 
First, it must provide predictable timing so application jobs meet their deadlines.
Second, it should minimize energy consumption given the timing requirement.
These two subproblems are intrinsically connected, but can be decoupled to provide a general solution.
The complexity arises from the need to keep resource allocation general with respect to the platform and the running application.
We tackle the problem of providing predictable timing using control theory by computing a \emph{generic control signal}.
Using the computed control signal, we solve the energy minimization problem using mathematical optimization.

\figref{poet-runtime} illustrates our approach.
The application informs the runtime of its target job latency.
Measuring each job start and completion time, POET's runtime computes a latency error and passes it to a \textbf{controller}.
The controller uses the error to calculate a generic control signal, indicating how much the application speed should be altered.
This signal is used by the \textbf{optimizer}, together with the specification of available resources, to schedule resource usage so that the desired speed is achieved and energy consumption is minimized.
Both the controller and the optimizer are designed independently of any particular application and system.
The only assumption made is that applications are composed of repeated jobs, each with a (soft real-time) deadline, or desired latency.
As we target multicore platforms, we assume each job may be processed by multiple, communicating threads.

\begin{figure}[t]
  \centering
  \input{img/poet/scheme.tex}
  % \vskip -.5em
  \caption{Overview of the POET runtime.}
  \label{fig:poet-runtime}
% \vskip -.3em
\end{figure}


\subsection{Controller}
\label{sec:controllerdesign}

The controller cancels the error between the desired job deadline $d_r$ and its measured latency $d_m(t)$ at time $t$.
We consider the error $e(t)$ using the abstraction of the job speed, where the required speed is $1/d_r$ and the measured speed at time $t$ is $1/d_m(t)$.
\begin{equation}
e(t) = \frac{1}{d_r} - \frac{1}{d_m(t)}
\label{eqn:poet-error}
\end{equation}
POET models latency as
\begin{equation}
d_m(t) = \frac{1}{s(t-1) \cdot b(t-1)}
\label{eqn:poet-latency}
\end{equation}
where $s(t)$ is the speedup to achieve with respect to $b(t)$, the base application speed, \ie the speed of the application when it uses the minimum amount of resources.
%
POET's controller uses the error computed with \eqnref{poet-error} to calculate the control signal $s(t)$ in \eqnref{poet-latency} so that the speedup cancels the error.
The controller intervenes at discrete time instants and implements the \emph{integral control law}~\cite{Hellerstein2004a}:
\begin{equation}
  s(t) = s(t-1) + (1-p) \cdot \frac{e(t)}{b(t)} 
  \label{eqn:poet-control}
\end{equation}
where $p$ is a configurable \emph{pole} of the closed loop characteristic equation~\cite{ICSE2014}.
To ensure the controller reaches a steady state where the error is eliminated without oscillations, the value of $p$ should lay in the unit circle, \ie $0 \le p < 1$. $p$ is user-configurable.
A small $p$ makes the controller highly reactive, while a large $p$ makes it slow to respond to external changes.
However, a large $p$ ensures robustness with respect to transient fluctuations and may be beneficial for very noisy systems.
A small $p$ will cause the controller to react quickly, potentially producing a noisy control signal.

The parameter $b(t)$ represents the application's base speed, which directly influences the controller.
Different applications will have different base speeds.
Applications may also experience \emph{phases}, where base speed changes over time.
To accommodate these situations, POET continually estimates base speed using a Kalman filter~\cite{welch2006kalman}, which adapts $b(t)$ of \eqnref{poet-control} to the current application behavior.
Assuming minimal measurement variance (\ie even if an application is noisy, the signaling framework does not add additional noise) and denoting the application timing variance as $q_b(t)$, the Kalman filter formulation is standard:
\begin{equation}
\left \lbrace
\begin{array}{rcl}
\hat{b}^{-}(t) & = & \hat{b}(t-1) \\
e^{-}_{b}(t) & = & e_{b}(t-1) + q_b(t) \\
k_b(t) 
  & = & \frac{e^{-}_{b}(t) \cdot s(t)}{[s(t)]^2
        \cdot e^{-}_{b}(t)} \\
\hat{b}(t) 
  & = & \hat{b}^{-}(t) + k_b(t) 
        \, \left[ \frac{1}{d_m(t)} - s(t) \cdot \hat{b}^{-}(t) \right] \\
e_{b}(t) & = & [1 - k_b(t) \cdot s(t-1)] \, e^{-}_{b}(t)
\end{array}
\right .
\label{eqn:kalman-filter}
\end{equation}
This formulates Kalman gain for the latency as $k_b(t)$, the \emph{a priori} and \emph{a posteriori} estimates of the base speed as $\hat{b}^{-}(t)$ and $\hat{b}(t)$, and the \emph{a priori} and \emph{a posteriori} estimates of the error variance as $e^{-}_{b}(t)$ and $e_{b}(t)$.
The Kalman filter produces a statistically optimal estimate of the system's parameters and is provably exponentially convergent~\cite{CaoSchwartz2003}.

A POET user does not need to know about Kalman filtering -- $s(t)$ is computed by the controller, $d_m(t)$ and $q_b(t)$ are measured, and all other filter parameters are derived.
The advantage of using the Kalman filter is that POET's formulation is independent of particular applications and systems.
% Computing the generic control signal $s(t)$ means that the controller does not reason about specific sets of resources, making it portable between systems.
% POET's control formulation is independent of a particular application as it uses the Kalman filter to estimate the application base speed.
Unlike prior work, this controller does not reason about a particular set of resources, but computes a generic control signal $s(t)$.
POET provides formal guarantees about its steady-state convergence and robustness without requiring users to understand control theory.


\subsection{Optimizer}
\label{sec:optimizer}

The optimizer turns the generic control signal computed by the controller into a system-specific resource allocation strategy, translating the speedup $s(t)$ computed with \eqnref{poet-control} into a \emph{schedule} for the available resources.
The schedule is computed for the next $\tau$ time units.
To meet the requirement on the target latency and avoid deadline misses, POET ensures that the application completes $I(t)$ jobs in the next interval\footnote{In our implementation, both the jobs to be completed and an acceptable scheduling period $\tau$ are specified by the application.}, with $I(t) = \tau \cdot s(t) \cdot b(t)$.

As shown in \figref{poet-runtime}, the optimizer takes, as input, a resource specification containing the set of available system configurations.
There are $C$ possible configurations in the system and by convention, we number the configurations from $0$ to $C-1$.
We use $c = 0$ to indicate the configuration where the least amount of resources is given to the application, corresponding to a low-power idle state or sleep state when available.
In contrast, configuration $C-1$ maximizes the resource availability.
Each configuration $c$ is associated with a power consumption $p_c$ and speedup $s_c$.

Given this information, POET schedules for each configuration $c$ an execution time $\tau_c$, ensuring that the $I(t)$ iterations complete and the total energy consumption is minimized. To do so, POET solves the following optimization problem:
\begin{eqnarray}
\minimize && \sum_{c=0}^{C-1} \tau_c \cdot p_c \label{eqn:poet-power} \\
\st %&& \nonumber\\
&& \sum_{c=0}^{C-1} \tau_c \cdot s_c \cdot b(t) =  I(t) \label{eqn:poet-work} \\
&& \sum_{c=0}^{C-1} \tau_c =  \tau \label{eqn:poet-deadline} \\
&& 0 \le \tau_c \le \tau, \qquad \forall c \in \{0,\ldots,C-1\} \label{eqn:poet-time}
\end{eqnarray}
\eqnref{poet-power} minimizes the total energy consumption.
\eqnref{poet-work} constrains all jobs to complete within the next control period.
\eqnref{poet-deadline} ensures that the time is fully scheduled and \eqnref{poet-time} imposes that a non-negative time is assigned to each configuration.
Solving linear optimization problems is, in general, hard.
However, this particular problem has a structure that makes it practical to solve.
Feasible solutions are confined to a polytope in the positive quadrant defined by the two constraints \eqnsref{poet-work}{poet-deadline}.
Thus, linear programming theory states an optimal solution exists for this problem when all the $\tau_c$ are equal to zero except for (at most) two configurations~\cite{LP}.

\begin{algorithm}[t]
  \caption{Finding a Minimal-Energy Schedule.}
  \begin{algorithmic}
    \footnotesize
    \Require $C$ \Comment{system configurations, given by user}
    \Require $s(t)$ \Comment{speedup, given by \eqnref{poet-control}}
    %\Require $b(t)$ \Comment{base application speed, given by \eqnref{kalman-filter}}
    %\Require $r_d$ \Comment{desired performance, given by application}
	\Require $\omega$ \Comment{discrete work units, given by application}
    \State $under = \{c \mid s_c \le s(t) \}$
	\State $over = \{c \mid s_c > s(t)\}$
    \State $candidates = \{\langle u, o \rangle \mid u \in under, o \in over\}$
    \State $energy = \infty$
    \State $optimal = \langle -1, -1 \rangle$
    \State $schedule = \langle 0, 0 \rangle$ \newline
    \For {$\langle u, o \rangle \in candidates$} \Comment{loop over all pairs}
	\State $\omega_u = \omega \cdot \left\lfloor \frac{s_o \cdot (s_u - s(t))}{s(t) \cdot (s_u - s_o)} \right\rfloor$
    % \State $\omega_u = \frac{\omega \cdot s(t) - \omega \cdot s_o}{s_u -s_o}$
  \Comment{compute the work units to spend in each configuration in pair}
    \State $\omega_o = \omega - \omega_u$
    \State $newEnergy = \omega_u \cdot p_u + \omega_o \cdot p_o$
	\Comment{compute energy of this pair}
    \If {$newEnergy < energy$}
  \Comment{compare energy to best found so far}
    \State $energy = newEnergy$
    \State $optimal = \langle u, o \rangle$
    \State $schedule = \langle \omega_u,\omega_o \rangle$
    \EndIf
    \EndFor \newline \newline
    \Return $optimal$ \Comment{pair of configurations with minimal energy} \newline
    \Return $schedule$ \Comment{work units to spend in each configuration}
  \end{algorithmic}
  \label{algo:poet-optimal}
\end{algorithm}

\TODO{Align this description with the algorithm, \ie using $\omega$ instead of $\tau$ (see MS thesis).}
\algoref{poet-optimal} takes the set of configurations, the controller's speedup, and the time interval $\tau$ specified by the application.
It then divides the configurations in two distinct sets.
The first set contains all configurations with a speedup less than or equal to the target.
The second contains the remaining configurations; \ie those with speedups greater than required.
Subsequently, \algoref{poet-optimal} loops over all possible pairs of configurations, with one from each set, to determine how much time should be spent in each configuration given the deadline.
If the energy of the pair is lower than any previous energy, the algorithm stores the current best pair, its energy, and its schedule.
When the algorithm terminates, its output is the pair of chosen configurations and their assigned times.
The algorithm tests all possible pairs from the two sets, each of which contains at most $C$ elements, so an upper bound to the algorithm complexity is $O(C^2)$.
We know that there is an optimal solution to the linear program with at most two non-zero $\tau_c$ (as the dual problem has two dimensions \cite{LP}) and \algoref{poet-optimal} tests all pairs of configurations.
Therefore, \algoref{poet-optimal} will find a minimal-energy schedule.


\subsection{Discussion of Generality and Robustness}
\label{sec:properties}

The controller and the optimizer both reason about speedup instead of absolute performance or latency.
The absolute performance of the application, measured by the average latency of its jobs, will vary as a function of the application itself and the platform it executes on.
However, speedup is a general concept and can be applied to any application and system, providing a more general metric for control.
Moreover, the controller customizes the behavior of a specific application using the estimate of its base speed produced by the Kalman filter
The optimizer operates in a platform-independent manner, using the available configurations provided as input to find the optimal solution, without relying on a particular heuristic that may be system-specific or application-dependent.
Finally, the customizable pole $p$ in \eqnref{poet-control} allows for flexibility and robustness to inaccuracies and noise.

The ability to control robustness to inaccuracies and model errors is a major advantage of feedback control systems~\cite{ICSE2014}
In particular, POET is stable and converges to the desired latency without oscillations provided that $0 \le p < 1$.
Formal analysis of this behavior can be obtained by applying standard control techniques---see the original POET publication for further details \cite{POET}.

In addition to provable convergence, the control formulation allows us to analyze POET's robustness to user error.
In particular, suppose $\Delta$ is a multiplicative error term, indicating the largest error in the speedup values provided in the system configurations.
That is, if the provided speedup is $s_p$, the real value is $s_p \cdot \Delta$.
POET cancels the error despite inaccurate information if and only if $0 < \Delta < 2/(1-p)$.
The value of $p$ therefore determines how robust POET is to errors in speedup specifications.
For example, when $p = 0.1$, $s_p$ can be off by a factor of $2$ and the system is still guaranteed to converge.
Users who can provide good system models will therefore use a small $p$, while less confident users can select a larger $p$.
All the experiments in our evaluation use $p=0$ to test our implementation in the least forgiving setting.
A detailed analysis of POET's robustness is presented in the original POET publication \cite{POET}.
